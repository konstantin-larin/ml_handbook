{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f99432c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import math\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchtext.data.metrics import bleu_score\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "502358aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads=8, ff_hidden_dim=2048, dropout=0.1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.attention = nn.MultiheadAttention(embedding_dim, num_heads, dropout, batch_first=True)        \n",
    "        self.norm_1 = nn.LayerNorm(embedding_dim)\n",
    "        self.norm_2 = nn.LayerNorm(embedding_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, ff_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_dim, embedding_dim)\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)        \n",
    "    def forward(self, x, mask=None):\n",
    "        attn_out, attn_weights = self.attention(x, x, x, key_padding_mask=mask)        \n",
    "        x = self.norm_1(x + self.dropout(attn_out))\n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm_2(x + self.dropout(ff_out))\n",
    "\n",
    "        return x, attn_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bd4e26c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, num_heads=8, ff_hidden_dim=2048, dropout=0.1, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.masked_attention = nn.MultiheadAttention(embedding_dim, num_heads, dropout, batch_first=True)\n",
    "        self.norm_1 = nn.LayerNorm(embedding_dim)\n",
    "        self.cross_attention = nn.MultiheadAttention(embedding_dim, num_heads, dropout, batch_first=True)\n",
    "        self.norm_2 = nn.LayerNorm(embedding_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embedding_dim, ff_hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(ff_hidden_dim, embedding_dim)\n",
    "        )\n",
    "        self.norm_3 = nn.LayerNorm(embedding_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "        self.masked_attention_weights_ = None\n",
    "        self.cross_attention_weights_ = None        \n",
    "    def forward(self, x, enc_outs, attn_mask=None, mask_1=None, mask_2=None):                \n",
    "        mask_attn_out, mask_attn_weights = self.masked_attention(x,x,x, attn_mask=attn_mask, key_padding_mask=mask_1)                \n",
    "        x = self.norm_1(x + self.dropout(mask_attn_out))                \n",
    "\n",
    "        cross_attn_out, cross_attn_weights = self.cross_attention(query=x, key=enc_outs, value=enc_outs, key_padding_mask=mask_2)                \n",
    "        x = self.norm_2(x + self.dropout(cross_attn_out))        \n",
    "        \n",
    "        ff_out = self.ff(x)\n",
    "        x = self.norm_3(x + self.dropout(ff_out))\n",
    "        return x, mask_attn_weights, cross_attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aab7ba34",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, max_len=5000, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        pe = torch.zeros(max_len, embedding_dim)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, embedding_dim, 2).float() * (-math.log(10000.) / embedding_dim))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "    def forward(self, x):\n",
    "        seq_len = x.size(1)\n",
    "        return x + self.pe[:, :seq_len, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d66422e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, pos_encoder, embedding_dim, \n",
    "                 input_vocab_size, input_pad_idx,\n",
    "                 output_vocab_size, output_pad_idx,\n",
    "                 bos_idx, eos_idx, \n",
    "                *args, **kwargs):\n",
    "        \n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "        self.input_embedding = nn.Embedding(input_vocab_size, embedding_dim, padding_idx=input_pad_idx)\n",
    "        self.output_embedding = nn.Embedding(output_vocab_size, embedding_dim, padding_idx=output_pad_idx)        \n",
    "        self.output_pad_idx = output_pad_idx\n",
    "        self.encoder = encoder\n",
    "        self.pos_encoder = pos_encoder\n",
    "        self.decoder = decoder\n",
    "        self.bos_idx = bos_idx\n",
    "        self.eos_idx = eos_idx        \n",
    "        \n",
    "        self.out = nn.Linear(embedding_dim, output_vocab_size)   \n",
    "\n",
    "\n",
    "    def forward(self, src, src_mask, tgt, tgt_mask):\n",
    "        src_emb = self.pos_encoder(self.input_embedding(src))\n",
    "        enc_outs, _ = self.encoder(src_emb, mask=src_mask)\n",
    "        \n",
    "        tgt_emb = self.pos_encoder(self.output_embedding(tgt[:, :-1])) #shift right\n",
    "        seq_len = tgt_emb.size(1)            \n",
    "        attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=src.device) * float('-inf'), diagonal=1)                \n",
    "\n",
    "        dec_outs, _, cross_attention_weights = self.decoder(tgt_emb, enc_outs, attn_mask=attn_mask, mask_1=tgt_mask[:, :-1], mask_2=src_mask)\n",
    "        logits = self.out(dec_outs)\n",
    "        return logits, cross_attention_weights\n",
    "    @torch.no_grad()\n",
    "    def predict(self, src, src_mask,  max_len=20):\n",
    "        batch_size = src.size(0)\n",
    "        src_emb = self.pos_encoder(self.input_embedding(src))\n",
    "        enc_outs,_ = self.encoder(src_emb, mask=src_mask)\n",
    "\n",
    "        y_pred = torch.full((batch_size, 1), self.bos_idx, dtype=torch.long, device=src.device)\n",
    "        finished = torch.zeros(batch_size, dtype=torch.bool, device=src.device)\n",
    "\n",
    "        for t in range(max_len):\n",
    "            tgt_emb = self.pos_encoder(self.output_embedding(y_pred))            \n",
    "            seq_len = tgt_emb.size(1)            \n",
    "            attn_mask = torch.triu(torch.ones(seq_len, seq_len, device=src.device) * float('-inf'), diagonal=1)                \n",
    "\n",
    "            dec_outs, _, cross_attention_weights = self.decoder(tgt_emb, enc_outs,attn_mask=attn_mask, mask_1=None, mask_2=src_mask)\n",
    "            logits = self.out(dec_outs[:, -1])\n",
    "            next_token = logits.argmax(-1).unsqueeze(1)\n",
    "            y_pred = torch.cat([y_pred, next_token], dim=1) \n",
    "            finished |= (next_token.squeeze(1) == self.eos_idx)\n",
    "            if finished.all():\n",
    "                break    \n",
    "        return y_pred, cross_attention_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6add1de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_corpus = [\n",
    "    (\"привет\", \"hello\"),\n",
    "    (\"как дела\", \"how are you\"),\n",
    "    (\"спасибо\", \"thank you\"),\n",
    "    (\"пока\", \"bye\"),\n",
    "    (\"доброе утро\", \"good morning\"),\n",
    "    (\"добрый вечер\", \"good evening\"),\n",
    "    (\"я люблю тебя\", \"i love you\"),\n",
    "    (\"что это\", \"what is this\"),\n",
    "    (\"где ты\", \"where are you\"),\n",
    "    (\"хорошо\", \"ok\"),\n",
    "]\n",
    "from collections import Counter\n",
    "\n",
    "def build_vocabs(sentences, min_freq=1):\n",
    "    counter = Counter()\n",
    "    for s in sentences:\n",
    "        counter.update(s.split())\n",
    "    word2idx = {'<pad>': 0, '<bos>': 1, '<eos>': 2, '<unk>': 3}\n",
    "    idx2word = {0: '<pad>', 1: '<bos>', 2: '<eos>', 3: '<unk>'}\n",
    "    for word, freq in counter.items():\n",
    "        if freq >= min_freq and word not in word2idx:\n",
    "            idx = len(word2idx)\n",
    "            word2idx[word] = idx\n",
    "            idx2word[idx] = word\n",
    "    return word2idx, idx2word\n",
    "\n",
    "\n",
    "src_sentences = [s for s, _ in toy_corpus]\n",
    "tr_sentences = [s for _, s in toy_corpus]\n",
    "src_w2i, src_i2w = build_vocabs(src_sentences)\n",
    "tr_w2i, tr_i2w = build_vocabs(tr_sentences)\n",
    "\n",
    "def encode(sentence, w2i, add_bos=False, add_eos=False):\n",
    "    tokens = []\n",
    "    if add_bos: tokens.append(w2i['<bos>'])\n",
    "    \n",
    "    for w in sentence.split():\n",
    "        tokens.append(w2i.get(w, w2i['<unk>']))        \n",
    "    \n",
    "    if add_eos: tokens.append(w2i['<eos>'])\n",
    "    return tokens\n",
    "\n",
    "def pad_batch(seqs, pad_idx):\n",
    "    max_len = max(len(s) for s in seqs)\n",
    "    return [s + [pad_idx] * (max_len-len(s)) for s in seqs]\n",
    "\n",
    "class ToyCorpusDataset(Dataset):\n",
    "    def __init__(self, corpus, src_w2i, tr_w2i):\n",
    "        super().__init__()\n",
    "        self.corpus = corpus\n",
    "        self.src_vocab = src_w2i\n",
    "        self.tr_vocab = tr_w2i\n",
    "    def __len__(self):\n",
    "        return len(self.corpus)\n",
    "    def __getitem__(self, index):\n",
    "        src, tr = self.corpus[index]\n",
    "        src_ids = encode(src, self.src_vocab)\n",
    "        tr_ids = encode(tr, self.tr_vocab, True, True)\n",
    "\n",
    "        return torch.tensor(src_ids), torch.tensor(tr_ids)\n",
    "\n",
    "def collate_fn(batch):\n",
    "    src_batch, tr_batch = zip(*batch)\n",
    "        \n",
    "    src_lens = torch.tensor([len(s) for s in src_batch])\n",
    "    tr_lens = torch.tensor([len(s) for s in tr_batch])\n",
    "        \n",
    "    src_padded = torch.tensor(pad_batch([s.tolist() for s in src_batch], src_w2i['<pad>']), dtype=torch.long)\n",
    "    tr_padded = torch.tensor(pad_batch([s.tolist() for s in tr_batch], tr_w2i['<pad>']), dtype=torch.long)\n",
    "        \n",
    "    src_mask = (src_padded == src_w2i['<pad>'])\n",
    "    tr_mask = (tr_padded == tr_w2i['<pad>'])\n",
    "    \n",
    "    return src_padded, src_mask, src_lens, tr_padded, tr_mask, tr_lens\n",
    "\n",
    "\n",
    "dataset = ToyCorpusDataset(toy_corpus, src_w2i, tr_w2i)\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f10f8cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = TransformerEncoder(embedding_dim=8, num_heads=2, ff_hidden_dim=8)\n",
    "decoder = TransformerDecoder(embedding_dim=8, num_heads=2, ff_hidden_dim=8)\n",
    "pos_encoder = PositionalEncoder(embedding_dim=8)\n",
    "transformer = Transformer(\n",
    "    encoder=encoder, decoder=decoder, pos_encoder=pos_encoder, embedding_dim=8, input_vocab_size=len(src_w2i),\n",
    "    input_pad_idx=src_w2i['<pad>'], output_vocab_size=len(tr_w2i), output_pad_idx=tr_w2i['<pad>'],\n",
    "    bos_idx=tr_w2i['<bos>'], eos_idx=tr_w2i['<eos>']\n",
    "    )\n",
    "optimizer = torch.optim.Adam(transformer.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss(ignore_index=tr_w2i['<pad>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05327d8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\konst\\Desktop\\ML\\yandex_ml_handbook\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:5137: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50. Loss: 1.2917, Bleu: 0.0000\n",
      "ref: ['good', 'evening']\n",
      "hyp: []\n",
      "ref: ['what', 'is', 'this']\n",
      "hyp: ['bye', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you']\n",
      "Epoch 100. Loss: 0.6337, Bleu: 0.0000\n",
      "ref: ['what', 'is', 'this']\n",
      "hyp: ['bye', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you']\n",
      "ref: ['hello']\n",
      "hyp: []\n",
      "Epoch 150. Loss: 0.3448, Bleu: 0.0000\n",
      "ref: ['good', 'morning']\n",
      "hyp: ['bye', 'you', 'you', 'you', 'you']\n",
      "ref: ['ok']\n",
      "hyp: []\n",
      "Epoch 200. Loss: 0.1681, Bleu: 0.0000\n",
      "ref: ['what', 'is', 'this']\n",
      "hyp: ['bye', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you', 'you']\n",
      "ref: ['bye']\n",
      "hyp: []\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "transformer.to(device)\n",
    "best_bleu=0.0\n",
    "early_stopping_rounds, early_stopping_rounds_counter = 1000, 0\n",
    "\n",
    "for epoch in range(1, 201):    \n",
    "    transformer.train()\n",
    "    total_loss = 0        \n",
    "    for src, src_mask, src_lens, tr, tr_mask, tr_lens in dataloader:        \n",
    "        src, tr = src.to(device), tr.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logits, _ = transformer(src, src_mask, tr, tr_mask)\n",
    "\n",
    "                \n",
    "        loss = loss_fn(\n",
    "            logits.reshape(-1, logits.size(2)),\n",
    "            tr[:, :logits.size(1)].reshape(-1),\n",
    "        )\n",
    "        \n",
    "        loss.backward()        \n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()    \n",
    "\n",
    "    transformer.eval()\n",
    "    candidate_corpus, references_corpus = [], []\n",
    "    with torch.no_grad():\n",
    "        for src, src_mask, src_lens, tr, tr_mask, tr_lens in dataloader:\n",
    "            src, tr = src.to(device), tr.to(device)\n",
    "            preds, _ = transformer.predict(src, src_mask)                    \n",
    "\n",
    "            for i in range(len(src)):\n",
    "                hyp = [tr_i2w[idx.item()] for idx in preds[i]\n",
    "                       if idx.item() not in  [tr_w2i['<pad>'], tr_w2i['<bos>'], tr_w2i['<eos>']]\n",
    "                ]\n",
    "                ref = [[tr_i2w[idx.item()] for idx in tr[i] \n",
    "                        if idx.item() not in [tr_w2i['<pad>'], tr_w2i['<bos>'], tr_w2i['<eos>']]]]\n",
    "                \n",
    "                candidate_corpus.append(hyp)\n",
    "                references_corpus.append(ref[0])            \n",
    "    bleu = bleu_score(candidate_corpus, references_corpus)\n",
    "\n",
    "    if bleu > best_bleu:\n",
    "        best_bleu = bleu\n",
    "        early_stopping_rounds_counter = 0\n",
    "    else:\n",
    "        early_stopping_rounds_counter += 1\n",
    "        if early_stopping_rounds_counter >= early_stopping_rounds:\n",
    "            print(f'Early stopping on epoch {epoch}, best BLEU {best_bleu:.4f}')\n",
    "            break    \n",
    "\n",
    "\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}. Loss: {total_loss/len(dataloader):.4f}, Bleu: {bleu:.4f}')        \n",
    "        for i in range(2):            \n",
    "            print('ref:', references_corpus[-i])        \n",
    "            print('hyp:', candidate_corpus[-i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84661d2b",
   "metadata": {},
   "source": [
    "Of course we need more data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
