{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0dc1fe12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d303a80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = ['I', 'like', 'cats', 'dogs', 'and']\n",
    "word2idx = {w: i for i,w in enumerate(vocab)}\n",
    "idx2word = {i: w for i, w in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71fbb504",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = [\n",
    "    [word2idx[w] for w in ['I','like', 'cats']],\n",
    "    [word2idx[w] for w in ['I', 'like', 'dogs']],\n",
    "    [word2idx[w] for w in ['cats', 'and', 'dogs']]\n",
    "]\n",
    "\n",
    "x = torch.tensor([seq[:-1] for seq in sequences])\n",
    "y = torch.tensor([seq[1:] for seq in sequences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d44ee9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 4\n",
    "embed = nn.Embedding(len(vocab), embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f8dbf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 8\n",
    "output_size = len(vocab)\n",
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda55078",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89a96c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.W_x = nn.Linear(input_size, hidden_size, False)        \n",
    "        self.W_h = nn.Linear(hidden_size, hidden_size, True)\n",
    "        self.W_y = nn.Linear(hidden_size, output_size, True)\n",
    "        self.hidden_size = hidden_size\n",
    "    def forward(self, x, h0=None):\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "        if h0 is None:\n",
    "            h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        else: h = h0\n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            xt = x[t]\n",
    "            h = torch.tanh(self.W_x(xt) + self.W_h(h))\n",
    "            y = self.W_y(h)\n",
    "            outputs.append(y.unsqueeze(0)) # seq_len, batch_size, vocab_len\n",
    "        return torch.cat(outputs, dim=0), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1220303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.2608\n",
      "Epoch 50: 1.1929\n",
      "Epoch 100: 1.1277\n",
      "Epoch 150: 1.0638\n",
      "Epoch 200: 1.0016\n",
      "Epoch 250: 0.9415\n",
      "Epoch 300: 0.8836\n",
      "Epoch 350: 0.8283\n",
      "Epoch 400: 0.7760\n",
      "Epoch 450: 0.7272\n",
      "Epoch 500: 0.6820\n"
     ]
    }
   ],
   "source": [
    "rnn = RNN(embedding_dim, output_size, hidden_size)\n",
    "optimizer = torch.optim.Adam(list(rnn.parameters()) + list(embed.parameters()), lr=3e-4)\n",
    "\n",
    "for epoch in range(501):        \n",
    "    optimizer.zero_grad()\n",
    "    x_emb_batch = embed(x).permute(1, 0, 2) #seq_len, batch_size, embedding_dim    \n",
    "    outputs, _ = rnn(x_emb_batch)    \n",
    "    outputs = outputs.permute(1, 0, 2) #batch_size, seq_len, vocab_size\n",
    "        \n",
    "    loss = loss_fn(outputs.reshape(-1, len(vocab)), y.reshape(-1))        \n",
    "    loss.backward()\n",
    "    optimizer.step()    \n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}: {loss:.4f}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81d205f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.1400,  0.0856,  1.1383,  0.9932,  0.3025]])\n",
      "cats\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_test = torch.tensor(\n",
    "        [[word2idx['I'], word2idx['like']]]\n",
    "        )\n",
    "    x_emb_test = embed(x_test).permute(1, 0, 2)\n",
    "    y_pred, _ = rnn(x_emb_test)\n",
    "    print(y_pred[-1])\n",
    "    predicted_idx = y_pred[-1].argmax(dim=-1)\n",
    "    print(idx2word[predicted_idx.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0cde39",
   "metadata": {},
   "source": [
    "# Bidirectional RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a43317d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BRNN(nn.Module):\n",
    "    class ForwardRNN(RNN):\n",
    "        pass\n",
    "    class BackwardRNN(RNN):\n",
    "        def forward(self, x, h0=None):\n",
    "            seq_len, batch_size, _ = x.size()\n",
    "            if h0 is None:\n",
    "                h = torch.zeros(batch_size, hidden_size,device=x.device)\n",
    "            else:\n",
    "                h = h0\n",
    "            outputs = []\n",
    "            for t in range(seq_len - 1, -1, -1):                \n",
    "                xt= x[t]\n",
    "                h = torch.tanh(self.W_x(xt) + self.W_h(h))\n",
    "                y = self.W_y(h)\n",
    "                outputs.append(y.unsqueeze(0))\n",
    "            return torch.cat(outputs, dim=0), h\n",
    "                \n",
    "            \n",
    "\n",
    "                        \n",
    "    def __init__(self, input_size, output_size, hidden_size, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        self.forward_rnn = BRNN.ForwardRNN(input_size, output_size, hidden_size)        \n",
    "        self.backward_rnn = BRNN.BackwardRNN(input_size, output_size, hidden_size)\n",
    "        self.out = nn.Linear(2 * output_size, output_size, True)\n",
    "    def forward(self, x, h0=None):\n",
    "        f_output, _ = self.forward_rnn(x, h0)\n",
    "        b_output, _ = self.backward_rnn(x, h0)\n",
    "        conc_output = torch.cat((f_output, b_output), dim=-1)\n",
    "        return self.out(conc_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "160b0f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.7647596597671509\n",
      "Epoch 50: 1.3231393098831177\n",
      "Epoch 100: 0.8804828524589539\n",
      "Epoch 150: 0.5359984636306763\n",
      "Epoch 200: 0.36696314811706543\n",
      "Epoch 250: 0.30078092217445374\n",
      "Epoch 300: 0.2727583050727844\n",
      "Epoch 350: 0.2587410509586334\n",
      "Epoch 400: 0.2507844865322113\n",
      "Epoch 450: 0.24584811925888062\n",
      "Epoch 500: 0.24257569015026093\n"
     ]
    }
   ],
   "source": [
    "brnn = BRNN(embedding_dim, output_size, hidden_size)\n",
    "optimizer = torch.optim.Adam(list(brnn.parameters()) + list(embed.parameters()))\n",
    "\n",
    "for epoch in range(501):\n",
    "    optimizer.zero_grad()\n",
    "    x_emb_batch = embed(x).permute(1, 0, 2)    \n",
    "    outputs = brnn(x_emb_batch)\n",
    "    outputs = outputs.permute(1, 0, 2)    \n",
    "\n",
    "    loss = loss_fn(outputs.reshape(-1, output_size), y.reshape(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f15f0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.2106,  5.4616, -3.2930, -1.0603,  0.0478])\n",
      "like\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_test = torch.tensor(\n",
    "        [[word2idx['I'], word2idx['like']]]\n",
    "        )\n",
    "    x_emb_test = embed(x_test).permute(1, 0, 2)\n",
    "    y_pred, _ = brnn(x_emb_test)\n",
    "    print(y_pred[-1])\n",
    "    predicted_idx = y_pred[-1].argmax(dim=-1)\n",
    "    print(idx2word[predicted_idx.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ddb05c7",
   "metadata": {},
   "source": [
    "# LSTM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1cacc160",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, *args, **kwargs):        \n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.W = nn.Linear(input_size + hidden_size, 4 * hidden_size, True)\n",
    "\n",
    "        self.W_y = nn.Linear(hidden_size, output_size, True)\n",
    "    def forward(self, x, h0=None, c0=None):\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "        if h0 is None:\n",
    "            h = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        else:\n",
    "            h = h0\n",
    "        \n",
    "        if c0 is None:\n",
    "            c = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        else:\n",
    "            c = c0\n",
    "\n",
    "        outputs = []                    \n",
    "        for t in range(seq_len):\n",
    "            xt = x[t]\n",
    "\n",
    "            concat = torch.cat([xt, h], dim=1)\n",
    "            gates = self.W(concat)\n",
    "            i, f, o, g = gates.chunk(4, dim=1)\n",
    "\n",
    "\n",
    "            i = torch.sigmoid(i) # input gate\n",
    "            f = torch.sigmoid(f) # forget gate\n",
    "            o = torch.sigmoid(o) # output gate\n",
    "            g = torch.tanh(g) # candidate\n",
    "\n",
    "            c = f * c + i * g\n",
    "            h = o * torch.tanh(c)\n",
    "\n",
    "            y = self.W_y(h)\n",
    "            outputs.append(y.unsqueeze(0))            \n",
    "        \n",
    "        return torch.cat(outputs, dim=0), (h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12990268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\konst\\Desktop\\ML\\yandex_ml_handbook\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.6627235412597656\n",
      "Epoch 50: 1.5630215406417847\n",
      "Epoch 100: 1.4226716756820679\n",
      "Epoch 150: 1.2098143100738525\n",
      "Epoch 200: 0.9696956276893616\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(embedding_dim, output_size, hidden_size)\n",
    "optimizer = torch.optim.Adam(list(lstm.parameters()) + list(embed.parameters()))\n",
    "\n",
    "for epoch in range(201):\n",
    "    optimizer.zero_grad()\n",
    "    x_emb_batch = embed(x).permute(1, 0, 2)    \n",
    "    outputs, _ = lstm(x_emb_batch)\n",
    "    outputs = outputs.permute(1, 0, 2)    \n",
    "\n",
    "    loss = loss_fn(outputs.reshape(-1, output_size), y.reshape(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64e9c2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.5851, -0.3156,  0.3743,  0.4750, -0.7708]])\n",
      "dogs\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_test = torch.tensor(\n",
    "        [[word2idx['I'], word2idx['like']]]\n",
    "        )\n",
    "    x_emb_test = embed(x_test).permute(1, 0, 2)\n",
    "    y_pred, _ = lstm(x_emb_test)\n",
    "    print(y_pred[-1])\n",
    "    predicted_idx = y_pred[-1].argmax(dim=-1)\n",
    "    print(idx2word[predicted_idx.item()])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1614de6",
   "metadata": {},
   "source": [
    "# GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9b78a6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRU(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.W = nn.Linear(input_size + hidden_size, 3 * hidden_size, bias=True)\n",
    "\n",
    "        self.W_y = nn.Linear(hidden_size, output_size, True)        \n",
    "    \n",
    "    def forward(self, x, h0=None):\n",
    "        seq_len, batch_size, _ = x.size()\n",
    "\n",
    "        if h0 is None:\n",
    "            h = torch.zeros(batch_size, self.hidden_size, device=x.device)            \n",
    "        else:\n",
    "            h= h0\n",
    "        \n",
    "        outputs = []\n",
    "        for t in range(seq_len):\n",
    "            xt = x[t]\n",
    "\n",
    "            combined = torch.cat([xt, h], dim=1)\n",
    "            gates = self.W(combined)\n",
    "            z, r, g = gates.chunk(3, dim=1)\n",
    "\n",
    "            z = torch.sigmoid(z) # update gate\n",
    "            r = torch.sigmoid(r) # reset gate\n",
    "\n",
    "            combined_candidate = torch.cat([xt, r * h], dim=1)\n",
    "            g = torch.tanh(self.W(combined_candidate)[:, 2 * self.hidden_size:])\n",
    "            h = (1 - z) * h + z * g # hidden state\n",
    "\n",
    "            y = self.W_y(h)\n",
    "            outputs.append(y.unsqueeze(0))\n",
    "\n",
    "        return torch.cat(outputs, dim=0), h    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c419811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 1.6938714981079102\n",
      "Epoch 50: 1.4758267402648926\n",
      "Epoch 100: 1.245678424835205\n",
      "Epoch 150: 0.9801347851753235\n",
      "Epoch 200: 0.7372898459434509\n"
     ]
    }
   ],
   "source": [
    "gru = GRU(embedding_dim, output_size, hidden_size)\n",
    "optimizer = torch.optim.Adam(list(gru.parameters()) + list(embed.parameters()))\n",
    "\n",
    "for epoch in range(201):\n",
    "    optimizer.zero_grad()\n",
    "    x_emb_batch = embed(x).permute(1, 0, 2)    \n",
    "    outputs, _ = gru(x_emb_batch)\n",
    "    outputs = outputs.permute(1, 0, 2)    \n",
    "\n",
    "    loss = loss_fn(outputs.reshape(-1, output_size), y.reshape(-1))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "832ef525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.9019, -0.5650,  0.6723,  1.1492, -1.1548]])\n",
      "dogs\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    x_test = torch.tensor(\n",
    "        [[word2idx['I'], word2idx['like']]]\n",
    "        )\n",
    "    x_emb_test = embed(x_test).permute(1, 0, 2)\n",
    "    y_pred, _ = gru(x_emb_test)\n",
    "    print(y_pred[-1])\n",
    "    predicted_idx = y_pred[-1].argmax(dim=-1)\n",
    "    print(idx2word[predicted_idx.item()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb496bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
