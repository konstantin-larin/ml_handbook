{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "WxtnUMCHUGXr"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "x = torch.ones(5)\n",
        "y = torch.zeros(3)\n",
        "W= torch.randn(5, 3, requires_grad=True)\n",
        "b = torch.randn(3)\n",
        "b.requires_grad_(True)\n",
        "z = x @ W + b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pc4jqO4zWUSg",
        "outputId": "cd54a1da-c062-40ab-b26c-3fffe5afc640"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x7f5265f2a530>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x7f5265f294b0>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss.backward()\n",
        "print(W.grad)\n",
        "print(b.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQMMr0vjW5MD",
        "outputId": "7d1fca11-911d-4d76-87e2-2627eaf26043"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.2561e-04, 1.5683e-02, 2.9972e-01],\n",
            "        [1.2561e-04, 1.5683e-02, 2.9972e-01],\n",
            "        [1.2561e-04, 1.5683e-02, 2.9972e-01],\n",
            "        [1.2561e-04, 1.5683e-02, 2.9972e-01],\n",
            "        [1.2561e-04, 1.5683e-02, 2.9972e-01]])\n",
            "tensor([1.2561e-04, 1.5683e-02, 2.9972e-01])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, W)+b\n",
        "print(z.requires_grad)\n",
        "\n",
        "with torch.no_grad():\n",
        "  z = torch.matmul(x, W)+b\n",
        "print(z.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DOpNxxCWZi46",
        "outputId": "43e14d06-df51-4357-f3c8-e90da7ab96cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = torch.matmul(x, W)+b\n",
        "z_det = z.detach()\n",
        "print(z_det.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPMUVXpaZ1G1",
        "outputId": "2cac5c1d-036f-4fdc-ec21-43a9956611d7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    }
  ]
}